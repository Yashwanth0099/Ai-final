{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f55cc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.applications import VGG19\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94e14c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93e56da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "train_path = '/Users/yash/Downloads/BrainTumourdetection/brain tumour dataset/Brain Tumor Training'\n",
    "test_path = '/Users/yash/Downloads/BrainTumourdetection/brain tumour dataset/Brain Tumour Testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "522ebc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_model = VGG19(input_shape=IMAGE_SIZE + [3],weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "552df78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg19_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aec89eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob('/Users/yash/Downloads/BrainTumourdetection/brain tumour dataset/Brain Tumor Training/*')\n",
    "x = Flatten()(vgg19_model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b10c7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 50178     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20074562 (76.58 MB)\n",
      "Trainable params: 50178 (196.01 KB)\n",
      "Non-trainable params: 20024384 (76.39 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "model = Model(inputs=vgg19_model.input, outputs=prediction)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc690cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12b2cc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4600 images belonging to 2 classes.\n",
      "Found 1872 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Make sure you provide the same target size as initialied for the image size\n",
    "train_generator = train_datagen.flow_from_directory('/Users/yash/Downloads/BrainTumourdetection/brain tumour dataset/Brain Tumor Training',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory('/Users/yash/Downloads/BrainTumourdetection/brain tumour dataset/Brain Tumour Testing',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52d70edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(vgg19_model)\n",
    "\n",
    "# Flatten the output and add a dense layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a73e177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "143/143 [==============================] - 1125s 8s/step - loss: 0.5492 - accuracy: 0.8113 - val_loss: 0.1899 - val_accuracy: 0.9300\n",
      "Epoch 2/30\n",
      "143/143 [==============================] - 1174s 8s/step - loss: 0.2003 - accuracy: 0.9232 - val_loss: 0.1394 - val_accuracy: 0.9526\n",
      "Epoch 3/30\n",
      "143/143 [==============================] - 1282s 9s/step - loss: 0.2107 - accuracy: 0.9153 - val_loss: 0.1241 - val_accuracy: 0.9537\n",
      "Epoch 4/30\n",
      "143/143 [==============================] - 1163s 8s/step - loss: 0.1275 - accuracy: 0.9514 - val_loss: 0.0918 - val_accuracy: 0.9709\n",
      "Epoch 5/30\n",
      "143/143 [==============================] - 1167s 8s/step - loss: 0.1557 - accuracy: 0.9400 - val_loss: 0.1320 - val_accuracy: 0.9467\n",
      "Epoch 6/30\n",
      "143/143 [==============================] - 1185s 8s/step - loss: 0.1057 - accuracy: 0.9641 - val_loss: 0.0711 - val_accuracy: 0.9747\n",
      "Epoch 7/30\n",
      "143/143 [==============================] - 1182s 8s/step - loss: 0.1196 - accuracy: 0.9540 - val_loss: 0.0705 - val_accuracy: 0.9763\n",
      "Epoch 8/30\n",
      "143/143 [==============================] - 1123s 8s/step - loss: 0.1117 - accuracy: 0.9536 - val_loss: 0.1198 - val_accuracy: 0.9488\n",
      "Epoch 9/30\n",
      "143/143 [==============================] - 1095s 8s/step - loss: 0.0866 - accuracy: 0.9689 - val_loss: 0.0446 - val_accuracy: 0.9871\n",
      "Epoch 10/30\n",
      "143/143 [==============================] - 1108s 8s/step - loss: 0.0717 - accuracy: 0.9729 - val_loss: 0.1107 - val_accuracy: 0.9569\n",
      "Epoch 11/30\n",
      "143/143 [==============================] - 1103s 8s/step - loss: 0.0761 - accuracy: 0.9715 - val_loss: 0.0428 - val_accuracy: 0.9855\n",
      "Epoch 12/30\n",
      "143/143 [==============================] - 1155s 8s/step - loss: 0.0645 - accuracy: 0.9777 - val_loss: 0.0350 - val_accuracy: 0.9887\n",
      "Epoch 13/30\n",
      "143/143 [==============================] - 1263s 9s/step - loss: 0.0467 - accuracy: 0.9840 - val_loss: 0.0419 - val_accuracy: 0.9865\n",
      "Epoch 14/30\n",
      "143/143 [==============================] - 1186s 8s/step - loss: 0.0455 - accuracy: 0.9840 - val_loss: 0.1049 - val_accuracy: 0.9591\n",
      "Epoch 15/30\n",
      "143/143 [==============================] - 1285s 9s/step - loss: 0.0628 - accuracy: 0.9783 - val_loss: 0.0655 - val_accuracy: 0.9758\n",
      "Epoch 16/30\n",
      "143/143 [==============================] - 1036s 7s/step - loss: 0.0446 - accuracy: 0.9834 - val_loss: 0.0261 - val_accuracy: 0.9914\n",
      "Epoch 17/30\n",
      "143/143 [==============================] - 1038s 7s/step - loss: 0.0423 - accuracy: 0.9849 - val_loss: 0.0338 - val_accuracy: 0.9892\n",
      "Epoch 18/30\n",
      "143/143 [==============================] - 1036s 7s/step - loss: 0.0399 - accuracy: 0.9858 - val_loss: 0.0542 - val_accuracy: 0.9752\n",
      "Epoch 19/30\n",
      "143/143 [==============================] - 1039s 7s/step - loss: 0.0363 - accuracy: 0.9877 - val_loss: 0.0490 - val_accuracy: 0.9811\n",
      "Epoch 20/30\n",
      "143/143 [==============================] - 1038s 7s/step - loss: 0.0503 - accuracy: 0.9823 - val_loss: 0.0254 - val_accuracy: 0.9941\n",
      "Epoch 21/30\n",
      "143/143 [==============================] - 1043s 7s/step - loss: 0.0369 - accuracy: 0.9871 - val_loss: 0.0275 - val_accuracy: 0.9935\n",
      "Epoch 22/30\n",
      "143/143 [==============================] - 1040s 7s/step - loss: 0.0454 - accuracy: 0.9820 - val_loss: 0.2292 - val_accuracy: 0.9176\n",
      "Epoch 23/30\n",
      "143/143 [==============================] - 1041s 7s/step - loss: 0.0557 - accuracy: 0.9812 - val_loss: 0.0932 - val_accuracy: 0.9666\n",
      "Epoch 24/30\n",
      "143/143 [==============================] - 1043s 7s/step - loss: 0.0273 - accuracy: 0.9901 - val_loss: 0.0198 - val_accuracy: 0.9941\n",
      "Epoch 25/30\n",
      "143/143 [==============================] - 1042s 7s/step - loss: 0.0388 - accuracy: 0.9866 - val_loss: 0.0308 - val_accuracy: 0.9860\n",
      "Epoch 26/30\n",
      "143/143 [==============================] - 1046s 7s/step - loss: 0.0343 - accuracy: 0.9884 - val_loss: 0.0111 - val_accuracy: 0.9957\n",
      "Epoch 27/30\n",
      "143/143 [==============================] - 1049s 7s/step - loss: 0.0787 - accuracy: 0.9694 - val_loss: 0.0290 - val_accuracy: 0.9871\n",
      "Epoch 28/30\n",
      "143/143 [==============================] - 1048s 7s/step - loss: 0.0242 - accuracy: 0.9923 - val_loss: 0.0166 - val_accuracy: 0.9952\n",
      "Epoch 29/30\n",
      "143/143 [==============================] - 1052s 7s/step - loss: 0.0420 - accuracy: 0.9851 - val_loss: 0.0280 - val_accuracy: 0.9919\n",
      "Epoch 30/30\n",
      "143/143 [==============================] - 1050s 7s/step - loss: 0.0293 - accuracy: 0.9888 - val_loss: 0.0121 - val_accuracy: 0.9973\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 32\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fad74baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 303s 5s/step\n",
      "Accuracy: 0.4995\n",
      "Precision: 0.5407\n",
      "Recall (Sensitivity): 0.5402\n",
      "Confusion Matrix:\n",
      "[[384 468]\n",
      " [469 551]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "y_true = test_generator.classes\n",
    "y_pred_raw = model.predict(test_generator)\n",
    "y_pred = (y_pred_raw > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "# Calculate accuracy, precision, recall, and confusion matrix\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall (Sensitivity): {recall:.4f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "489abb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "\n",
    "model.save('Brain Tumour1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf6c34e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db697430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e036657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd784de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e38f5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "model=load_model('Brain Tumour1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6bbffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/Users/yash/Downloads/project /Dataset/Testing/no_tumor/image(1).jpg'  # Change this to the path of your brain image\n",
    "img = utils.load_img(img_path, target_size=(224, 224))\n",
    "img_array = utils.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78963a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 220ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.3060563e-14]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(img_array)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "011d9d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is Normal\n"
     ]
    }
   ],
   "source": [
    "if prediction[0][0] >= 0.5:\n",
    "         print(\"Tumour detected\")\n",
    "else:\n",
    "        print(\"Result is Normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ba1683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
